% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
  \usepackage{soul}
\fi

% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage{fvextra}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{
  commandchars=\\\{\},
  breaklines, breaknonspaceingroup, breakanywhere
}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Impact of working remotely on social wellbeing and productivity},
  pdfauthor={Amaury Chartier; Valentine Salvat; Thomas Blondel; Elisa Rigazzio},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Impact of working remotely on social wellbeing and productivity}
\author{Amaury Chartier \and Valentine Salvat \and Thomas
Blondel \and Elisa Rigazzio}
\date{2025-12-08}
\begin{document}
\maketitle
\begin{abstract}
This is the abstract of the report. It should be a short summary of the
project, the data, the analysis and the results. It should be concise
and to the point. It should not be longer than 250 words.
\end{abstract}


\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-important-color!10!white, left=2mm, colframe=quarto-callout-important-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Interpretation \textgreater{} Visualization}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

\textbf{Plots alone won't earn you a good grade.} What matters most is
\textbf{interpreting your findings}.

For every result you present:

\begin{itemize}
\tightlist
\item
  \textbf{Explain} what the data shows
\item
  \textbf{Interpret} what it means for your research questions
\item
  \textbf{Discuss} implications and connect to domain knowledge
\end{itemize}

Quality of insight \textgreater{} Quantity of plots. Your instructors
can read plots---show them you \emph{understand} what the data reveals.

\end{tcolorbox}

\subsection*{Quarto Guide (Remove
After)}\label{quarto-guide-remove-after}
\addcontentsline{toc}{subsection}{Quarto Guide (Remove After)}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Two Report Writing Options}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

\textbf{Option 1 - Modular (Recommended for Teams):}

\begin{itemize}
\tightlist
\item
  Each section in a separate \texttt{.qmd} file in
  \texttt{report/sections/}
\item
  Files prefixed with \texttt{\_} (e.g., \texttt{\_introduction.qmd})
  are auto-included
\item
  Better for collaboration (fewer merge conflicts)
\item
  Render \texttt{report.qmd} to build the complete report
\end{itemize}

\textbf{Option 2 - Single File:}

\begin{itemize}
\tightlist
\item
  Write everything in \texttt{report.qmd}
\item
  Simpler but harder to collaborate
\item
  Delete \texttt{report/sections/} folder if using this approach
\end{itemize}

See \href{https://quarto.org/docs/authoring/includes}{Quarto includes
documentation} for details.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{What Are Code Chunks?}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

\textbf{Code chunks} are blocks of executable code embedded in your
Quarto document. They run when you render and include their output
(plots, tables, results) in your report.

\textbf{Basic Syntax:}

\begin{itemize}
\tightlist
\item
  Start with three backticks followed by the language:
  \texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}python}
\item
  Write your code
\item
  End with three backticks:
  \texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{itemize}

\textbf{Example:}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{data }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{: [}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{], }\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{: [}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{]\})}
\BuiltInTok{print}\NormalTok{(data)}
\end{Highlighting}
\end{Shaded}

\textbf{Chunk Options} (use \texttt{\#\textbar{}\ option:\ value} at the
top):

\begin{itemize}
\tightlist
\item
  \texttt{\#\textbar{}\ echo:\ false} - Hide code, show only output
\item
  \texttt{\#\textbar{}\ eval:\ false} - Show code but don't run it
\item
  \texttt{\#\textbar{}\ output:\ false} - Run code but hide output
\item
  \texttt{\#\textbar{}\ warning:\ false} - Suppress warning messages
\item
  \texttt{\#\textbar{}\ fig-cap:\ "My\ Plot"} - Add figure caption
\item
  \texttt{\#\textbar{}\ label:\ fig-myplot} - Label for
  cross-referencing
\end{itemize}

\textbf{Inline Code:} Use single backticks with \texttt{\{python\}} to
insert values in text: \texttt{4} → 4

See
\href{https://quarto.org/docs/computations/execution-options.html}{Quarto
code cells documentation} for all options.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-note-color!10!white, left=2mm, colframe=quarto-callout-note-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Interactive Plots in PDF}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Interactive plots/tables only work in HTML output. If using interactive
elements, render to HTML only (comment out the \texttt{pdf:} format
option).

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Code Visibility by Format}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

The YAML header controls code display:

\begin{itemize}
\tightlist
\item
  \textbf{HTML}: Code is collapsible (readers can show/hide)
\item
  \textbf{PDF/DOCX}: Code is hidden (only results shown)
\end{itemize}

\textbf{Override for specific chunks:}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#| echo: true   \# Show in all formats}
\CommentTok{\#| echo: false  \# Hide in all formats}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Writing Math Equations}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Use LaTeX syntax for mathematical notation:

\textbf{Inline:}
\texttt{\$\textbackslash{}bar\{x\}\ =\ \textbackslash{}frac\{1\}\{n\}\textbackslash{}sum\_\{i=1\}\^{}\{n\}x\_i\$}
→ \(\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i\)

\textbf{Display:} Use \texttt{\$\$...\$\$} for separate lines: \[
S(t) = P(T > t) = 1 - F(t)
\]

\textbf{Numbered (for referencing):}
\begin{equation}\phantomsection\label{eq-loss-ratio}{
\text{Loss Ratio} = \frac{\text{Incurred Losses}}{\text{Earned Premium}}
}\end{equation}

Reference with \texttt{@eq-loss-ratio} → Equation~\ref{eq-loss-ratio}

\textbf{Common symbols:} \(\alpha\), \(\beta\), \(\sigma\), \(\mu\),
\(\sum_{i=1}^{n}\), \(\int_a^b f(x)dx\), \(E[X]\), \(\text{Var}(X)\)

More at \href{https://en.wikibooks.org/wiki/LaTeX/Mathematics}{LaTeX
Math Symbols}.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Cross-Referencing Sections, Figures, Tables, and Equations}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Quarto automatically numbers and creates clickable links for:

\textbf{Sections:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\#\# Appendix A: Additional Plots \{\#sec{-}appendix{-}plots\}}

\NormalTok{Reference with: @sec{-}appendix{-}plots}
\end{Highlighting}
\end{Shaded}

\textbf{Figures:}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#| label: fig{-}correlation}
\CommentTok{\#| fig{-}cap: "Correlation matrix"}

\NormalTok{Reference }\ControlFlowTok{with}\NormalTok{: }\OperatorTok{@}\NormalTok{fig}\OperatorTok{{-}}\NormalTok{correlation}
\end{Highlighting}
\end{Shaded}

\textbf{Tables:}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#| label: tbl{-}summary}
\CommentTok{\#| tbl{-}cap: "Summary statistics"}

\NormalTok{Reference }\ControlFlowTok{with}\NormalTok{: }\OperatorTok{@}\NormalTok{tbl}\OperatorTok{{-}}\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\textbf{Equations:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{$$ y = mx + b $$ \{\#eq{-}linear\}}

\NormalTok{Reference with: @eq{-}linear}
\end{Highlighting}
\end{Shaded}

\textbf{Working examples in this template:}

\begin{itemize}
\tightlist
\item
  ``As discussed in Section~\ref{sec-appendix-plots}, we provide
  additional visualizations.''
\item
  ``See Figure~\ref{fig-comparison} for the debugging workflow.''
\item
  ``Individual images like Figure~\ref{fig-before} and
  Figure~\ref{fig-after} can also be referenced.''
\end{itemize}

\textbf{Note:} Use the same \texttt{@label} syntax for figures, tables,
and equations. Quarto automatically numbers them and creates clickable
links.

See
\href{https://quarto.org/docs/authoring/cross-references.html}{Quarto
Cross-References} for more.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{HTML Tabsets}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Organize content into tabs, which are like container boxes for the
content (HTML only, and not PDF/DOCX). They allow you to:

\begin{itemize}
\tightlist
\item
  \textbf{Organize multiple related visualizations} without cluttering
  the page
\item
  \textbf{Show different views} of the same data (distribution, summary,
  box plot)
\item
  \textbf{Compare approaches} side-by-side (e.g., different plotting
  libraries)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.panel{-}tabset\}}
\FunctionTok{\#\# Tab 1}
\NormalTok{Content}
\FunctionTok{\#\# Tab 2}
\NormalTok{More content}
\FunctionTok{\#\# Tab 3}
\NormalTok{Excessive amount of content}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\subsection{Tab 1}

Content

\subsection{Tab 2}

More content

\subsection{Tab 3}

Excessive amount of content

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Including External Images and Files}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

\textbf{Basic image syntax:}

\begin{Shaded}
\begin{Highlighting}[]
\AlertTok{![Caption](path/to/image.png)}
\end{Highlighting}
\end{Shaded}

\textbf{With sizing and attributes:}

\begin{Shaded}
\begin{Highlighting}[]
\AlertTok{![My figure](images/plot.png)}\NormalTok{\{width=80\% fig{-}align="center"\}}
\end{Highlighting}
\end{Shaded}

\textbf{Images with cross-references:}

\begin{Shaded}
\begin{Highlighting}[]
\AlertTok{![Distribution analysis](images/histogram.png)}\NormalTok{\{\#fig{-}histogram\}}

\NormalTok{As shown in @fig{-}histogram, the data is normally distributed.}
\end{Highlighting}
\end{Shaded}

\textbf{Common image paths:}

\begin{itemize}
\tightlist
\item
  Relative to current file: \texttt{images/plot.png}
\item
  From project root: \texttt{../data/plots/figure.png}
\item
  Absolute path: \texttt{C:/Users/Name/project/images/plot.png} (avoid
  for reproducibility)
\end{itemize}

\textbf{Supported formats:} PNG, JPG, SVG, PDF (PDF only in PDF output)

\textbf{Pro tip:} Store images in \texttt{report/images/} folder for
organization.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Markdown Text Formatting}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

\textbf{Basic formatting:}

\begin{itemize}
\tightlist
\item
  \textbf{Bold text:} \texttt{**bold**} or \texttt{\_\_bold\_\_} →
  \textbf{bold}
\item
  \emph{Italic text:} \texttt{*italic*} or \texttt{\_italic\_} →
  \emph{italic}
\item
  \textbf{\emph{Bold and italic:}} \texttt{***both***} →
  \textbf{\emph{both}}
\end{itemize}

\textbf{Note:} Markdown doesn't have built-in underline. For underline,
use HTML:

\begin{itemize}
\tightlist
\item
  Underlined text:
  \texttt{\textless{}u\textgreater{}underlined\textless{}/u\textgreater{}}
  → underlined
\end{itemize}

\textbf{Other useful formatting:} - \texttt{Inline\ code:} `code` →
\texttt{code} - Superscript: \texttt{X\^{}2\^{}} → X\textsuperscript{2}
- Subscript: \texttt{H\textasciitilde{}2\textasciitilde{}O} →
H\textsubscript{2}O - \st{Strikethrough:}
\texttt{\textasciitilde{}\textasciitilde{}text\textasciitilde{}\textasciitilde{}}
→ \st{strikethrough}

\textbf{Headings:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\# Heading 1}
\FunctionTok{\#\# Heading 2}
\FunctionTok{\#\#\# Heading 3}
\FunctionTok{\#\#\#\# Heading 4}
\end{Highlighting}
\end{Shaded}

\textbf{Lists:}

\begin{Shaded}
\begin{Highlighting}[]
\SpecialStringTok{{-} }\NormalTok{Unordered item}
\SpecialStringTok{{-} }\NormalTok{Another item}
\SpecialStringTok{  {-} }\NormalTok{Nested item (2 spaces indent)}

\SpecialStringTok{1. }\NormalTok{Ordered item}
\SpecialStringTok{2. }\NormalTok{Second item}
\SpecialStringTok{   1. }\NormalTok{Nested (3 spaces indent)}
\end{Highlighting}
\end{Shaded}

\textbf{Links:}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{[}\OtherTok{Link text}\CommentTok{](https://url.com)}
\CommentTok{[}\OtherTok{Link with title}\CommentTok{](https://url.com "Hover text")}
\end{Highlighting}
\end{Shaded}

\textbf{Blockquotes:}

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{\textgreater{} This is a quote}
\AttributeTok{\textgreater{} It can span multiple lines}
\end{Highlighting}
\end{Shaded}

See
\href{https://quarto.org/docs/authoring/markdown-basics.html}{Markdown
Guide} for more.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-note-color!10!white, left=2mm, colframe=quarto-callout-note-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Including External Images}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Store external figures (diagrams, charts, screenshots) in
\texttt{report/images/} and include them in your report.

\textbf{Basic syntax:}

\begin{Shaded}
\begin{Highlighting}[]
\AlertTok{![Caption](images/your{-}image.png)}\NormalTok{\{\#fig{-}label width=70\% fig{-}align="center"\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example - Multiple images side by side with cross-references:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{\#fig{-}comparison layout{-}ncol=2 layout{-}valign="bottom"\}}

\AlertTok{![Before debugging](images/meme1.jpg)}\NormalTok{\{\#fig{-}before width=100\%\}}

\AlertTok{![After debugging](images/meme2.jpeg)}\NormalTok{\{\#fig{-}after width=100\%\}}

\NormalTok{The emotional journey of a data scientist debugging their code}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\begin{figure}

\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/meme1.jpg}

}

\subcaption{\label{fig-before}Before debugging}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/meme2.jpeg}

}

\subcaption{\label{fig-after}After debugging}

\end{minipage}%

\caption{\label{fig-comparison}The emotional journey of a data scientist
debugging their code}

\end{figure}%

\textbf{Key options:}

\begin{itemize}
\tightlist
\item
  \texttt{layout-ncol=2} - Two columns (each 50\% width)
\item
  \texttt{layout-valign="bottom"} - Align by bottom edge
\item
  \texttt{width=100\%} - Fill entire column
\item
  \texttt{fig-align="center"} - Center single images
\end{itemize}

\textbf{Supported formats:}

\begin{itemize}
\tightlist
\item
  \textbf{All outputs:} PNG, JPG/JPEG
\item
  \textbf{HTML only:} WEBP, SVG, GIF
\item
  \textbf{PDF only:} PDF images
\end{itemize}

See the \href{https://quarto.org/docs/authoring/figures.html}{Quarto
Figures documentation} for advanced layouts, subcaptions, and complex
figure arrangements.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Controlling Python (Code) Generated Figure Size}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

\textbf{For Python matplotlib plots}, figure size is controlled
\textbf{in your Python code} using \texttt{figsize}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Standard readable size}
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{5}\NormalTok{))  }\CommentTok{\# width, height in inches}

\CommentTok{\# Smaller figure}
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{))}

\CommentTok{\# Larger figure}
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\textbf{Why \texttt{figsize} in code?} When you use
\texttt{plt.subplots(figsize=...)} or \texttt{plt.figure(figsize=...)},
matplotlib creates the image at that exact size. Quarto chunk options
like \texttt{\#\textbar{}\ fig-width:} and
\texttt{\#\textbar{}\ fig-height:} are ignored because the figure size
is already determined by your Python code.

\textbf{To resize figures after creation:}

Use the \texttt{width} attribute in curly braces (works for any image):

\begin{Shaded}
\begin{Highlighting}[]
\AlertTok{![My plot](path/to/plot.png)}\NormalTok{\{width=70\%\}}
\end{Highlighting}
\end{Shaded}

Or in the chunk options (only for formats without explicit
\texttt{figsize}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#| fig{-}width: 7}
\CommentTok{\#| fig{-}height: 5}
\end{Highlighting}
\end{Shaded}

\textbf{Recommended workflow:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set \texttt{figsize} in your Python code to a readable default (e.g.,
  \texttt{figsize=(8,\ 5)})
\item
  If the figure appears too large/small in your report, adjust the
  \texttt{figsize} values proportionally
\item
  Keep aspect ratio consistent: divide/multiply both dimensions by the
  same factor
\end{enumerate}

\textbf{Good default sizes:}

\begin{itemize}
\tightlist
\item
  Small plot: \texttt{figsize=(6,\ 4)}
\item
  Standard plot: \texttt{figsize=(8,\ 5)}
\item
  Large plot: \texttt{figsize=(10,\ 6)}
\item
  Wide plot: \texttt{figsize=(10,\ 4)}
\item
  Square plot: \texttt{figsize=(6,\ 6)}
\end{itemize}

\textbf{Pro tip:} DPI (dots per inch) also affects quality. Matplotlib
default is 100, but for publications use
\texttt{plt.savefig(\textquotesingle{}plot.png\textquotesingle{},\ dpi=300)}
if you need high-resolution images.

\end{tcolorbox}

\section{Introduction}\label{introduction}

\subsection{Project Goals}\label{project-goals}

Describe the main goals of the project, including the motivation behind
the research and the key questions you aim to answer.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Writing Tip: Make it Relevant}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Connect your project to real-world actuarial or insurance problems. For
example, if analyzing claim data, explain how your insights could
improve risk assessment or pricing strategies.

\end{tcolorbox}

\subsection{Research Questions}\label{research-questions}

\begin{itemize}
\tightlist
\item
  Question 1: \ldots{}
\item
  Question 2: \ldots{}
\item
  (Add as necessary)
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-important-color!10!white, left=2mm, colframe=quarto-callout-important-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Research Question Quality}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Good research questions are:

\begin{itemize}
\tightlist
\item
  \textbf{Specific}: Clearly defined and focused
\item
  \textbf{Measurable}: Can be answered with data
\item
  \textbf{Relevant}: Connected to the project goals
\item
  \textbf{Feasible}: Can be addressed with available data and methods
\end{itemize}

\end{tcolorbox}

\subsection{Related Work}\label{related-work}

Discuss relevant academic papers, methodologies, and prior research that
informed your project. Include both domain-specific literature
(actuarial science, insurance, finance) and methodological references
(statistical methods, data science techniques).

\textbf{Example structure:}

\begin{itemize}
\tightlist
\item
  \textbf{Domain literature}: Academic papers on your topic (e.g.,
  claims analysis, mortality modeling, risk assessment)
\item
  \textbf{Methodological references}: Statistical methods or data
  science techniques you applied
\item
  \textbf{Course materials}: Azizi (2025) provides Python-based data
  science techniques for actuarial applications
\item
  \textbf{Technical resources}: Books like McKinney (2022) and
  VanderPlas (2016) for implementation details
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Academic Citations Recommended}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Your Related Work section can have \textbf{more value when including
academic papers (further evidence)} from peer-reviewed journals or
conference proceedings, not just books or course materials. Use Google
Scholar, university library databases, or specialized actuarial journals
to find relevant papers.

\textbf{Recommended sources:}

\begin{itemize}
\tightlist
\item
  Academic journals (Insurance: Mathematics and Economics, ASTIN
  Bulletin, Journal of Risk and Insurance)
\item
  Conference papers (actuarial conferences, data science symposiums)
\item
  Working papers from researchers in your field
\end{itemize}

\textbf{Citation example}: ``Azizi \& Rudnytskyi (2022) investigated
multi-modal approaches to real estate rental price prediction,
demonstrating that models combining tabular data with visual information
(property images and satellite imagery) outperform traditional methods
relying solely on structured features. Their supervised learning
framework fused dedicated neural network branches for each data type,
achieving superior performance on 11,105 Swiss rental listings.''
\emph{(This reference is already in your \texttt{references.bib} file
and can be cited as \texttt{@azizi2022realestate})}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-note-color!10!white, left=2mm, colframe=quarto-callout-note-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Citing Sources}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Always cite your sources properly! In Quarto, use
\texttt{@citation\_key} syntax. The bibliography will be automatically
generated from the \texttt{references.bib} file.

\textbf{Example}: \texttt{@azizi2025dsas} renders as: Azizi (2025)

Add entries to \texttt{references.bib} in
\href{https://www.bibtex.com/g/bibtex-format/}{BibTeX} format for all
sources you cite (every article normally generates BibTeX, otherwise
search an online tool that does it).

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-warning-color!10!white, left=2mm, colframe=quarto-callout-warning-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Avoiding Plagiarism}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Make sure to cite all sources that informed your work, including:

\begin{itemize}
\tightlist
\item
  Datasets (with URLs)
\item
  Methods or techniques from papers or tutorials
\item
  Code snippets adapted from online resources
\item
  Inspiration from existing analyses
\end{itemize}

When in doubt, cite it!

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-caution-color!10!white, left=2mm, colframe=quarto-callout-caution-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Common Mistake}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Don't just list your research questions without context. Explain
\textbf{why} each question matters and \textbf{how} it relates to your
dataset and project goals.

\end{tcolorbox}

\section{Data}\label{data}

\subsection{Sources}\label{sources}

The dataset used in this project is the 2020 Remote Working Survey, part
of the NSW Remote Working Survey series, publicly available through the
New South Wales Government's Open Data Portal. ``Data source:
\href{https://data.nsw.gov.au/data/dataset/nsw-remote-working-survey}{Remote
working survey 2020}''\,''

The 2020 survey was conducted during August and September 2020 and aimed
to understand workers experiences and attitudes toward remote and hybrid
working following the first phase of the COVID-19 pandemic to study the
impact of remote work on professional and personal well-being.

To be eligible, respondents had to:

\begin{itemize}
\tightlist
\item
  be employed NSW residents\\
\item
  have experience of remote working in their current job After excluding
  unemployed individuals and those whose occupations cannot be performed
  remotely (dentists, cashiers, cleaners), the sample represents
  approximately 59\% of NSW workers.
\end{itemize}

This dataset is the 2020 wave of the survey. A second wave was collected
in March and April 2021. For the present analysis, only the 2020 dataset
is being processed and explored. Once the analysis of this wave is
finalized, it will be possible to extend the project by including and
comparing the 2021 dataset to identify how remote work patterns evolved
over time.

\subsection{Description}\label{description}

The cleaned 2020 NSW Remote Working Survey dataset contains four main
types of variables: categorical, ordinal, numeric, and binary.

\begin{itemize}
\item
  The categorical variables describe qualitative characteristics of
  respondents and their employment context, such as Industry, Job\_type,
  Organisation\_Size, Household, and Years\_in\_job. These variables are
  stored as text and provide context for grouping and comparison across
  sectors or demographic profiles.
\item
  The ordinal variables represent ordered responses on Likert scales,
  reflecting opinions and perceptions about remote working. Variables
  such as Org\_encouraged\_remote\_last\_year,
  Collaboration\_remote\_last\_year, Org\_encouraged\_remote\_3\_months,
  and Collaboration\_remote\_3\_months are encoded numerically from 1
  (``Strongly disagree'') to 5 (``Strongly agree''), allowing for
  quantitative analysis of attitudes.
\item
  The numeric variables capture measurable quantities including time
  allocation, remote work proportions, and productivity. Examples
  include Age, Remote\_pct\_last\_year, Preferred\_remote\_last\_year,
  Productivity\_remote\_vs\_workplace, and several variables
  representing hours spent on commuting, working, and personal or
  domestic activities. These are stored as integers or floats, making
  them suitable for descriptive statistics and correlation analysis.
\item
  The binary variables (Gender, Managing\_position) indicate Male/Femal
  or Yes/No conditions, encoded as 0 and 1. These variables enable
  comparisons between distinct groups.
\end{itemize}

The dataset also contains several important pieces of metadata that
ensure its quality and usability for analysis. Each observation is
identified by a unique respondent code (Response\_ID), which guarantees
traceability and prevents duplication during data processing.

In addition, all variable names were standardized to concise,
descriptive identifiers (Org\_encouraged\_remote\_last\_year) to make
the variables easier to read, reuse, and analyze in statistical
software. This naming convention makes the analysis process simpler and
clearer throughout the project.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-note-color!10!white, left=2mm, colframe=quarto-callout-note-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Dataset Overview Template}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

\begin{itemize}
\tightlist
\item
  \textbf{File used}: 2020\_rws-updated.csv
\item
  \textbf{Format}: CSV (comma-separated values)
\item
  \textbf{Encoding}: latin-1 (ISO-8859-1) (Remark: when loading the
  dataset in Python (Google Colab), attempting to read with utf-8 caused
  a UnicodeDecodeError due to typographic apostrophes and special
  characters. The correct parameter encoding latin1 was required to
  successfully load the data.)
\item
  \textbf{Memory usage}: approximately 7.46 MB
\item
  \textbf{Number of observations}: 1507 respondents (1507 rows)
\item
  \textbf{Number of variables}: 73 columns
\item
  \textbf{Time period}: August and September 2020
\item
  \textbf{Geographic coverage}: New South Wales, Australia
\item
  \textbf{Key variables}: Gender, Age, Job\_type, Organisation\_Size,
  Managing\_position, Remote\_pct\_last\_year,
  Preferred\_remote\_last\_year, Org\_encouraged\_remote\_last\_year,
  Collaboration\_remote\_last\_year, Productivity\_remote\_vs\_workplace
\end{itemize}

\end{tcolorbox}

\subsection{Loading Data}\label{loading-data}

For the moment, the dataset used in this report is the original raw CSV
file, loaded in its initial form for documentation purposes. All data
cleaning, transformations, and recoding steps are currently being
carried out in Google Colab, where the full preprocessing workflow is
developed and tested. Once this cleaning process is fully completed, the
resulting dataset will be exported again as a new, clean CSV file (e.g.,
remote\_working\_2020\_clean.csv). This cleaned version will then be
imported into the Quarto environment for the final stages of the
project.

Following best practices, the file is loaded using a relative path via
project\_root, ensuring that the document remains fully reproducible
regardless of the execution location. Because the original file
contained specific typographic characters that caused decoding issues
during import, the dataset is read using the latin-1 encoding.

After loading the file, several checks were performed to confirm correct
import: verification of the dataset dimensions, inspection of column
names and data types (df.info()), preview of the first rows to ensure
values were properly formatted. These steps guarantee that the dataset
is correctly imported and ready for subsequent exploratory analysis.

\subsection{Wrangling}\label{wrangling}

Document the data preprocessing steps taken, including cleaning,
transformation, and any merging of datasets.

Several preprocessing and wrangling steps were performed to prepare the
dataset for analysis. Before detailing each transformation.

All preprocessing steps described below are fully reproducible and
validated. Each transformation relies on deterministic Python operations
(such as replace(), rename(), astype(), or simple arithmetic), meaning
that re-running the same code on the raw dataset will always produce
identical results. After every transformation, checks such as head(),
value\_counts(), or describe() were used to validate that the
modifications were correctly applied and that the resulting values were
coherent (age ranges, Likert scales, or percentage conversions).

\textbf{Variable Duplicated}

Before any transformation, it is essential to verify that each
observation in the dataset is unique. Duplicate rows can bias the
analysis by over representing certain respondents or records.
Identifying and removing them ensures data integrity.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Code (duplicated)}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

df{[}df.duplicated(keep=False){]}

\#delete all the columns with think are not significant to lower the
size of the dataset for better readibility

cols\_to\_drop = {[}0,4\ldots..{]} + list(range(41, 73)) df =
df.drop(df.columns{[}cols\_to\_drop{]}, axis=1)

\end{tcolorbox}

This operation can be rerun on the raw dataset at any stage of the
workflow, guaranteeing consistent detection of duplicated records.

The command returned an empty DataFrame, confirming that no duplicate
rows were present. Therefore, no observations were removed in this step.

\textbf{Rename Columns}

Renaming the original survey questions into shorter and clearer variable
names was necessary to improve readability and make the dataset easier
to work with.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Code (rename column)}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

rename\_map = \{

\begin{verbatim}
"Response ID": "Response_ID", 

"What year were you born?": "Age", 

..... 

"On a day when you do remote work, how many hours would you spend doing the following activities? - Caring and 
domestic responsibilities": "Domestic_hours_remote"} 
\end{verbatim}

df.rename(columns=rename\_map, inplace=True)

\end{tcolorbox}

\textbf{Standard Name Organisation Size}

The Organisation\_Size variable was recoded by replacing the long
original text categories with shorter, standardised. To make grouping
and comparison more intuitive.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Code (standard name Organisation Size)}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

df{[}``Organisation\_Size''{]} =
df{[}``Organisation\_Size''{]}.replace(\{

\begin{verbatim}
"I am the only employee": "Solo business",

"Between 1 and 4": "Micro enterprise",
\end{verbatim}

\ldots..

\begin{verbatim}
"More than 200": "Large / Corporate enterprise"}).fillna("Other / Unspecified")
\end{verbatim}

\end{tcolorbox}

\textbf{Binary Variables}

The variables Gender and Managing\_position, the original text responses
were converted into binary categories to make them suitable for
statistical analysis and group comparisons. Respondents who selected
``Rather not say'' for gender were removed, as this category represented
only two individuals and could not form a meaningful subgroup. Gender
was then encoded as 0 = Male and 1 = Female, while Managing\_position
was encoded as 0 = No and 1 = Yes, indicating whether the respondent
supervises others. This transformation produces clean, consistent, and
analysis-ready binary variables that can be easily used in descriptive
statistics, visualisations, and modelling.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Code (Binary: Gender \& Managing Position)}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

df = df{[}df{[}``Gender''{]} != ``Rather not say''{]}

df{[}``Gender''{]} = df{[}``Gender''{]}.replace(\{``Male'': 0,
``Female'': 1\}).astype(``category'')

df{[}``Managing\_position''{]} =
df{[}``Managing\_position''{]}.replace(\{``No'': 0, ``Yes'':
1\}).astype(``category'')

df = df.dropna(subset={[}``Managing\_position''{]})

\end{tcolorbox}

\textbf{Variable Ages}

The variable Age, the dataset originally reported the respondent's year
of birth. This information was converted into a more interpretable age
variable by subtracting the birth year from 2020, the year the survey
was conducted. For example, a respondent born in 1985 becomes 2020 −
1985 = 35 years old. Expressing this information directly as age is more
intuitive and easier to interpret in descriptive statistics,
comparisons, and visualisations.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Code (Calculate age: convert birth year into age (as of 2020))}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

df{[}``Age''{]} = 2020 - df{[}``Age''{]}

\end{tcolorbox}

\textbf{Variable Years in Job}

The variable Years\_in\_job, the original responses were long text
categories describing tenure intervals. These were simplified into
shorter and more readable labels: ``5+'', ``5-'', and ``1-''. This
transformation keeps the original meaning while making the variable
easier to interpret, compare, and visualise in tables and plots.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Code (Years in job)}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

df{[}``Years\_in\_job''{]} = df{[}``Years\_in\_job''{]}.replace(\{

\begin{verbatim}
"More than 5 years": "5+",

"Between 1 and 5 years": "5-",

"Between 6 and 12 months": "1-"})
\end{verbatim}

\end{tcolorbox}

\textbf{Variable Likert Scale Mapping}

The Likert-scale variables, this transformation allows these subjective
perceptions to be analysed quantitatively. The four variables related to
organisational support and collaboration were mapped using this scale.
Any missing responses were replaced with the neutral value 3,
corresponding to ``Neither agree nor disagree'', to keep these
observations in the dataset while avoiding bias from missing attitudes.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Code (Likert scale mapping)}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

likert\_mapping = \{

\begin{verbatim}
"Strongly disagree": 1,
"Somewhat disagree": 2,
"Neither agree nor disagree": 3,
"Somewhat agree": 4,
"Strongly agree": 5}
\end{verbatim}

likert\_cols = {[}

\begin{verbatim}
"Org_encouraged_remote_last_year",
"Collaboration_remote_last_year",
"Org_encouraged_remote_3_months",
"Collaboration_remote_3_months"]
\end{verbatim}

df{[}likert\_cols{]} =
df{[}likert\_cols{]}.replace(likert\_mapping).fillna(3)

\end{tcolorbox}

\textbf{Variables Working Remotely}

The variables describing the percentage of time spent or preferred
working remotely, the original responses (``Less than 10\% of my
time''\ldots{}``100\% - All of my time''). These were first converted
into numeric percentage values using a mapping dictionary. All four
percentage-related variables were processed in the same way. Before
applying the mapping, non-breaking spaces (\xa0) and extra whitespace
were removed from the strings to avoid parsing issues. After the text
values were mapped to numeric percentages (``80\%'' → 80), the values
were converted into proportions between 0 and 1 by dividing by 100.

For example: 80 becomes 0.80 50 becomes 0.50 0 becomes 0.00

This final step creates clean numerical variables that can be easily
averaged, compared, or visualised in the analysis.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Code (Remote Percentages Mapping)}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

remote\_mapping = \{

\begin{verbatim}
"Rarely or never": 0,
"Less than 10% of my time": 5,

.....

"40%": 40,
"50% - About half of my time": 50,
"50% - I spent about half of my time remote working": 50,

.....

"90%": 90,
"100% - All of my time": 100,
"100% - I spent all of my time remote working": 100,
"I would not have preferred to work remotely": 0}
\end{verbatim}

percent\_cols = {[}

\begin{verbatim}
"Preferred_remote_last_year",
"Remote_pct_last_year",
"Remote_pct_last_3_months",
"Preferred_remote_3_months"]
\end{verbatim}

for col in percent\_cols:

\begin{verbatim}
df[col] = df[col].astype(str).str.replace("\xa0", "", regex=True).str.strip().replace(remote_mapping)

df[col] = pd.to_numeric(df[col], errors="coerce") / 100  # Convert to proportion
\end{verbatim}

\end{tcolorbox}

\textbf{Variables Productivity Cleaning}

The variable Productivity\_remote\_vs\_workplace, the survey responses
(I'm 20\% more productive when I work remotely'' or ``I'm 10\% less
productive''). These text responses were converted into clean numeric
values using a custom parsing function. The mapping works as follows:
Statements indicating more productive remotely return a positive
percentage (``20\% more productive'' → +20). Statements indicating less
productive remotely return a negative percentage (``10\% less
productive'' → --10). Statements indicating no difference return 0. This
transformation results in a numeric scale where positive values mean
higher productivity when working remotely, negative values reflect lower
productivity, and zero indicates no change. This allows the variable to
be analysed quantitatively, averaged across groups, or used in
visualisations.

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, left=2mm, colframe=quarto-callout-tip-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Code (Productivity Cleaning)}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

def parse\_productivity(val):

\begin{verbatim}
if pd.isna(val):
    return None

val = str(val).replace("\x92", "'")  # Fix apostrophe

if "more productive" in val:
    return int(val.split("%")[0].replace("I'm ", "").strip())

elif "less productive" in val:
    return -int(val.split("%")[0].replace("I'm ", "").strip())

elif "same" in val:
    return 0

return None
\end{verbatim}

df{[}``Productivity\_remote\_vs\_workplace''{]} = df

{[}``Productivity\_remote\_vs\_workplace''{]}.apply(parse\_productivity)

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, titlerule=0mm, bottomtitle=1mm, breakable, leftrule=.75mm, toprule=.15mm, colback=white, opacityback=0, colbacktitle=quarto-callout-caution-color!10!white, left=2mm, colframe=quarto-callout-caution-color-frame, toptitle=1mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Spotting Mistakes and Missing Data}, rightrule=.15mm, arc=.35mm, coltitle=black, bottomrule=.15mm]

Before conducting the analysis, the dataset was reviewed to identify
missing values, inconsistencies, and unusually small categories. This
ensures that only reliable and interpretable data are used in the
following steps.

\textbf{Identified missing data}

\begin{itemize}
\item
  Most variables contained very few missing values, mainly in
  attitudinal questions where some respondents simply did not answer.
\item
  Additional missingness appeared when converting textual inputs
  (percentages or productivity statements) into numeric formats, entries
  that could not be parsed were intentionally converted to NaN.
\item
  The inspection of category sizes showed that some groups were
  extremely small, such as the ``Rather not say'' gender category (2
  respondents), which was removed because it cannot support meaningful
  analysis.
\end{itemize}

\begin{quote}
\textbf{Warning}

\textbf{Detected anomalies}

\begin{itemize}
\item
  Age variable: Two respondents appear with an age of 120 years, which
  is biologically impossible and indicates a clear data entry error.
  This type of anomaly commonly occurs when the birth year is
  mistyped---for example, entering 1900 instead of 2000, or 2005 instead
  of 1920---which produces unrealistic age values. These observations
  will therefore be removed, while other extreme but plausible ages
  (such as 75 or 83) are retained at this stage. The minimum value (19)
  is plausible for entry-level workers.
\item
  Domestic\_hours\_workplace: A single observation of --1 hour is
  impossible and indicates a recording error.
\item
  Working and commuting time variables: Extremely high records were
  observed, such as 23 hours of work in a day or 10--12 hours of
  commuting.
\end{itemize}

While unlikely, these may represent exceptional cases (long-distance
travel, extended shifts). They are retained unless later analysis shows
they distort results.

\begin{itemize}
\item
  Commute\_hours\_remote: Values up to 12 hours on remote days are
  implausible and likely due to misinterpretation or input mistakes.
\item
  Productivity variable: Extreme values (+50\%, --50\%) appear in the
  data but remain plausible since the question explicitly asked
  respondents to report percentage differences.
\item
  Following best practices

  \begin{itemize}
  \tightlist
  \item
    Impossible values (age = 120, domestic hours = --1) will be removed
    before modelling.
  \item
    Extreme but plausible behaviours (very long workdays) are kept
    unless they later bias model results.
  \item
    Additional outliers identified during the analysis phase may be
    removed, flagged, or grouped depending on their relevance and
    impact.
  \end{itemize}
\end{itemize}

Outliers are not always errors; some reveal meaningful variability in
remote work habits. The chosen approach maintains data integrity while
ensuring that the analysis focuses on realistic, interpretable patterns.

The following EDA sections will further analyse these variables to
understand their patterns and relationships.

\section{EDA}\label{eda}

\begin{quote}
\textbf{Exploratory Data Analysis (EDA) Purpose}

The goal of EDA is to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Understand} the structure and patterns in your data
\item
  \textbf{Identify} relationships between variables
\item
  \textbf{Detect} anomalies, outliers, and data quality issues
\item
  \textbf{Generate} hypotheses for further analysis
\item
  \textbf{Choose} appropriate statistical methods
\end{enumerate}

Good EDA combines \textbf{visualizations} + \textbf{summary statistics}
+ \textbf{domain knowledge}.
\end{quote}

\begin{quote}
\textbf{Interpretation is Key!}

\textbf{Creating plots is only half the work.} The most important part
of EDA is \textbf{interpreting} what your visualizations reveal about
the data.

For \textbf{every plot} you create, you must:

\begin{itemize}
\tightlist
\item
  \textbf{Describe} what the plot shows (patterns, trends,
  distributions)
\item
  \textbf{Explain} why these patterns matter for your research questions
\item
  \textbf{Connect} findings to your project goals and domain context
\item
  \textbf{Justify} subsequent analysis decisions based on these insights
\end{itemize}

\textbf{A plot without interpretation is meaningless.} Your grade
depends heavily on the quality of your interpretations, not just the
number of plots you create.
\end{quote}

\subsection{Univariate Analysis}\label{univariate-analysis}

Examine each variable individually to understand its distribution,
central tendency, and spread.

\subsection{Distribution Plot}

\subsection{Summary Statistics}

\subsection{Box Plot}

\subsection{Bivariate Analysis}\label{bivariate-analysis}

Explore relationships between two variables.

Our univariate analysis in \textbf{?@fig-performance-dist} revealed that
performance scores follow an approximately normal distribution with a
mean of 0.90. The box plot (\textbf{?@fig-performance-box}) confirmed
this finding and helped identify a few outliers at the lower end of the
distribution.

\begin{quote}
\textbf{How to Reference Figures}

Use \texttt{@fig-label} syntax to reference figures in your text. Quarto
automatically numbers them and creates clickable links.

\textbf{Examples with figures in this template:}

\begin{itemize}
\tightlist
\item
  \texttt{@fig-performance-dist} → See \textbf{?@fig-performance-dist}
  for details
\item
  \texttt{@fig-correlation-matrix} → As shown in
  \textbf{?@fig-correlation-matrix}
\item
  \texttt{@tbl-anova-test} → The ANOVA results in
  \textbf{?@tbl-anova-test}
\end{itemize}

\textbf{Why reference figures?}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Automatic numbering (updates if you reorder)
\item
  Clickable links in HTML output
\item
  Professional academic writing standard
\item
  Helps readers find the relevant visualization
\end{enumerate}

\textbf{Example usage in text:}

``The distribution shown in \textbf{?@fig-performance-dist}
indicates\ldots{}''

``As seen in \textbf{?@fig-correlation-matrix}, there is a strong
positive correlation\ldots{}''
\end{quote}

Now let's examine how performance varies across different instructors.

\subsection{Grouped Comparison}

\subsection{Statistical Test}

\begin{quote}
\textbf{Plot Quality Requirements}

Every plot in your report should have:

✓ \textbf{Clear title} that explains what's being shown\\
✓ \textbf{Labeled axes} with units when applicable\\
✓ \textbf{Legend} if multiple groups/series are shown\\
✓ \textbf{Appropriate color scheme} (colorblind-friendly)\\
✓ \textbf{Proper sizing} (readable text, not too small/large)\\
✓ \textbf{Figure caption} using \texttt{fig-cap} option

\textbf{Poor plots = Poor grades!} Take time to make your visualizations
publication-quality.
\end{quote}

\subsection{Correlation Analysis}\label{correlation-analysis}

\subsection{Correlation Heatmap}

\subsection{Scatter Plot}

\subsection{Key Findings}\label{key-findings}

\textbf{Remember: Interpretation is more important than the plots
themselves!} Each finding below not only states \emph{what} we observe
but also \emph{why} it matters and \emph{what} it means for our
analysis.

Summarize the main insights from your exploratory analysis.
\textbf{Always reference your figures when discussing findings and
provide thorough interpretation!}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Distribution patterns}: The performance scores shown in
  \textbf{?@fig-performance-dist} follow an approximately normal
  distribution with a mean of

  \textbf{Interpretation}: This normal distribution suggests that most
  students perform around the average, with fewer students at the
  extremes (very high or very low scores). The relatively small standard
  deviation indicates consistent performance across the group. This
  pattern is typical in educational settings and suggests that the
  assessment was well-calibrated meaning not too easy (which would cause
  ceiling effects) nor too difficult (which would cause floor effects).
  The normality assumption also validates the use of parametric
  statistical tests for subsequent analyses.
\item
  \textbf{Outliers and data quality}: The box plot
  (\textbf{?@fig-performance-box}) reveals minimal outliers, with only a
  few observations falling below the lower whisker.

  \textbf{Interpretation}: The scarcity of outliers suggests good data
  quality and consistent measurement. The few low-performing outliers
  warrant further investigation - they could represent students who
  faced unusual circumstances or measurement errors. However, their
  small number means they are unlikely to significantly impact our
  overall conclusions. This finding gives us confidence in proceeding
  with the full dataset without extensive outlier removal.
\item
  \textbf{Group differences}: \textbf{?@fig-performance-by-instructor}
  demonstrates noticeable variation in performance across different
  instructors, with some instructors showing higher median scores than
  others. The ANOVA test (\textbf{?@tbl-anova-test}) confirms these
  differences are

  \textbf{Interpretation}: It also indicates that comparing students
  across different sections requires careful consideration. From a
  policy perspective, this might warrant investigating whether certain
  teaching methods are more effective or whether grading standards need
  to be harmonized across sections.
\item
  \textbf{Relationships}: The correlation matrix
  (\textbf{?@fig-correlation-matrix}) reveals several interesting
  patterns:

  \begin{itemize}
  \tightlist
  \item
    Strong positive correlation (r = between Experience and Salary
  \item
    Moderate positive correlation (r =) between Experience and
    Performance
  \item
    Weak correlation (r =) between Age and Performance
  \end{itemize}

  \textbf{Interpretation}: The Experience-Salary correlation aligns with
  economic theory that experience is rewarded in labor markets. The
  Experience-Performance correlation suggests that experience
  contributes to better performance, though other factors clearly matter
  as well. Interestingly, Age shows minimal correlation with
  Performance, suggesting that chronological age alone doesn't predict
  success - what matters is relevant experience. These patterns will
  guide our variable selection for predictive modeling, favoring
  Experience over Age as a key predictor.
\item
  \textbf{Experience-Performance relationship}:
  \textbf{?@fig-scatter-experience-performance} clearly shows a positive
  linear relationship, with more experienced individuals tending to have
  higher performance scores. The correlation coefficient is `

  \textbf{Interpretation}: The linear relationship visible in the
  scatter plot confirms that experience has a consistent, positive
  effect on performance. However, the substantial scatter around the
  regression line indicates that experience alone doesn't determine
  performance - individual differences and other factors play important
  roles. This suggests that while experience is valuable, organizations
  shouldn't rely solely on it when making hiring or promotion decisions.
\end{enumerate}

\begin{quote}
\textbf{Common Mistakes in Interpretation}

\textbf{Observation (not interpretation):} ``The histogram shows a
normal distribution.''\\
\textbf{Why it's insufficient:} This only describes what you see - it's
an observation, not an interpretation. You need to explain what it
\emph{means} and \emph{why it matters}.

\textbf{Good interpretation (observation + story):} ``The histogram
shows a normal distribution (mean = 0.90, sd = 0.05), which indicates
consistent performance across students. This pattern validates the use
of parametric statistical tests in our subsequent analysis. The tight
distribution suggests the assessment was well-calibrated, effectively
distinguishing between ability levels without ceiling or floor effects
that would compress scores.''

\textbf{Remember:}

\begin{itemize}
\tightlist
\item
  \textbf{Observation} = What you see in the data/plot
\item
  \textbf{Interpretation} = The story behind it - what it means, why it
  matters, what implications it has
\item
  \textbf{Always do both!} State the observation, then interpret its
  significance.
\end{itemize}
\end{quote}

\begin{quote}
\textbf{Common Mistake: Not Referencing Figures}

\textbf{Bad:} ``The histogram shows a normal distribution.''\\
\textbf{Good:} ``As shown in \textbf{?@fig-performance-dist}, the
histogram reveals a normal distribution.''

\textbf{Why?}

\begin{itemize}
\tightlist
\item
  Helps readers locate the relevant visualization
\item
  Creates professional, academic-style writing
\item
  Enables automatic figure numbering and links
\end{itemize}
\end{quote}

\begin{quote}
\textbf{From EDA to Analysis}

Use your EDA findings to:

\begin{itemize}
\tightlist
\item
  \textbf{Refine research questions} based on observed patterns
\item
  \textbf{Select appropriate statistical methods} based on data
  distributions
\item
  \textbf{Identify variables} for inclusion in models
\item
  \textbf{Justify transformations} (e.g., log transform for skewed data)
\item
  \textbf{Set expectations} for what you might find in formal analysis
\end{itemize}
\end{quote}

\section{\texorpdfstring{Methods \emph{(optional, only if you have
models)}}{Methods (optional, only if you have models)}}\label{methods-optional-only-if-you-have-models}

\begin{quote}
\textbf{When to Include This Section}

Include a Methods section if you:

\begin{itemize}
\tightlist
\item
  Apply statistical models (linear regression, logistic regression,
  etc.)
\item
  Perform hypothesis testing
\item
  Use machine learning algorithms
\item
  Conduct advanced statistical analyses
\end{itemize}

If your project is primarily exploratory (descriptive statistics and
visualizations only), you can skip this section or keep it minimal.
\end{quote}

Outline the statistical methods or models selected, along with the
rationale for their selection.

\textbf{Important}: Don't just show model output, \textbf{explain your
choices}:

\begin{itemize}
\tightlist
\item
  \textbf{Why} did you choose this particular method?
\item
  \textbf{What} assumptions does it make, and do your data meet them?
\item
  \textbf{How} does this method help answer your research questions?
\end{itemize}

\begin{quote}
\textbf{Interpretation is Essential!}

After showing model results, you \textbf{must interpret them}:

\textbf{Example interpretation:}

``The Poisson regression model identifies three significant predictors
of insurance claim frequency. Vehicle age shows a positive coefficient
(β = 0.08, p \textless{} 0.01), indicating that each additional year of
vehicle age increases expected claims by approximately 8\%. Driver age
has a negative coefficient (β = -0.02, p \textless{} 0.001), meaning
older drivers file fewer claims. The urban location dummy variable (β =
0.15, p \textless{} 0.05) suggests urban drivers have 15\% higher claim
rates than rural drivers.

However, the model's pseudo-R² of 0.22 indicates that these predictors
explain only 22\% of claim variation. Unobserved factors like driving
behavior, road conditions, and individual risk tolerance likely account
for the remaining variation. This suggests that while demographic
variables are useful for pricing, insurers should not rely solely on
them for risk assessment.''

\textbf{Remember}: Model output without interpretation demonstrates
technical skills but not understanding!
\end{quote}

\section{Findings and Discussion}\label{findings-and-discussion}

Provide your results or observations from applying statistical methods,
then \textbf{discuss them thoroughly} in the context of your research
questions and project goals.

\begin{quote}
\textbf{Structure Your Discussion}

A good discussion:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{States the finding} clearly (reference tables/figures)
\item
  \textbf{Interprets the result} (what does it mean?)
\item
  \textbf{Connects to research questions} (how does it answer your
  questions?)
\item
  \textbf{Relates to domain knowledge} (does it align with theory or
  prior research?)
\item
  \textbf{Acknowledges limitations} (what are the caveats?)
\item
  \textbf{Suggests implications} (what should we do with this
  information?)
\end{enumerate}

\textbf{Example}: ``Our regression analysis shows that experience
significantly predicts performance (β = 0.01, p \textless{} 0.001),
supporting our hypothesis that skill develops over time. This aligns
with learning curve theory in organizational psychology and suggests
that training programs should emphasize sustained practice. However, the
wide confidence interval (95\% CI: {[}0.005, 0.015{]}) indicates
substantial individual variation, meaning experience alone cannot
guarantee high performance.''
\end{quote}

\section{Conclusion}\label{conclusion}

\begin{quote}
\textbf{Structure of a Strong Conclusion}

A good conclusion section includes three key components:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Summary}: Recap your project goals, approach, and main
  findings
\item
  \textbf{Limitations}: Honestly discuss constraints and potential
  weaknesses
\item
  \textbf{Future Work}: Suggest concrete, specific next steps for
  extending the analysis
\end{enumerate}

Each subsection should be substantial - avoid generic statements!
\end{quote}

\subsection{Summary}\label{summary}

\textbf{Overview:} Summarize what has been achieved, including key
insights from your analysis and EDA. This should be written so that
someone reading only this section can understand your project and key
findings without reading the entire report.

\textbf{What to include:}

\begin{itemize}
\tightlist
\item
  Restate your research questions briefly
\item
  Summarize your approach (data, methods)
\item
  Highlight 3-5 main findings with their implications
\item
  Connect findings back to your project goals
\end{itemize}

\textbf{Length}: Aim for 1-2 substantial paragraphs that synthesize your
work.

\begin{quote}
\textbf{Common Mistake: Too Vague}

\textbf{Bad}: ``We analyzed the data and found some interesting
patterns.''

\textbf{Good}: ``This project investigated the relationship between
customer demographics and insurance claim frequencies using a dataset of
5,000 policyholders. Our exploratory analysis revealed that age and
vehicle type were the strongest predictors of claim frequency, with
older drivers (60+) filing 40\% fewer claims than younger drivers (under
25). Logistic regression analysis identified three key risk factors:
driver age, vehicle age, and urban vs rural location. These findings
suggest that current pricing models may underweight geographic factors.
For insurance practitioners, this implies that incorporating more
granular location data could improve risk segmentation and reduce
adverse selection.''

\textbf{Why it's good}: Specific about data, methods, key findings with
concrete numbers, and practical implications.
\end{quote}

\subsection{Limitations}\label{limitations}

Honestly discuss the constraints and potential weaknesses of your
analysis. \textbf{Strong projects acknowledge limitations!}

\textbf{Consider:}

\begin{itemize}
\tightlist
\item
  \textbf{Data limitations}: Sample size, missing data, measurement
  issues, lack of certain variables
\item
  \textbf{Methodological limitations}: Simplifying assumptions, choice
  of methods, inability to establish causation
\item
  \textbf{Scope limitations}: Time constraints, focus on specific
  aspects only
\item
  \textbf{Generalizability}: Can your findings apply beyond your
  specific dataset?
\end{itemize}

\textbf{Be specific}: Don't just say ``small sample size'' - explain
what impact this has on your conclusions.

\begin{quote}
\textbf{Why Limitations Matter}

Acknowledging limitations shows:

\begin{itemize}
\tightlist
\item
  \textbf{Critical thinking}: You understand the boundaries of your
  analysis
\item
  \textbf{Scientific integrity}: You're honest about what your study can
  and cannot show
\item
  \textbf{Maturity}: You recognize no analysis is perfect
\end{itemize}

\textbf{This improves your grade}, not reduces it! Instructors expect
students to think critically about their work.
\end{quote}

\subsection{Future Work}\label{future-work}

Outline specific next steps for extending or improving the analysis.
\textbf{Be concrete and realistic.}

\textbf{Good future work suggestions:}

\begin{itemize}
\tightlist
\item
  \textbf{Collect additional data}: ``Gather data from additional
  semesters to increase sample size and assess temporal stability of
  instructor effects''
\item
  \textbf{Apply advanced methods}: ``Implement mixed-effects models to
  account for nested data structure (students within instructors)''
\item
  \textbf{Test additional hypotheses}: ``Examine whether instructor
  effects vary by student prior knowledge using interaction terms''
\item
  \textbf{Expand scope}: ``Include qualitative data from student
  evaluations to understand mechanisms behind performance differences''
\end{itemize}

\textbf{Avoid vague statements like:}

\begin{itemize}
\tightlist
\item
  ❌ ``Get more data''
\item
  ❌ ``Use more variables''
\item
  ❌ ``Apply machine learning''
\end{itemize}

\textbf{Instead, be specific about WHAT, WHY, and HOW:}

\begin{itemize}
\tightlist
\item
  ✅ ``Collect data on student study hours to control for effort as a
  confounding variable, which would help isolate the true causal effect
  of instructor quality on performance''
\end{itemize}

\begin{quote}
\textbf{Connecting Everything}

Your conclusion should feel like a natural ending that:

\begin{itemize}
\tightlist
\item
  Circles back to your introduction (research questions)
\item
  Synthesizes your findings from EDA and analysis
\item
  Demonstrates you've thought deeply about your project
\item
  Leaves readers with clear takeaways
\end{itemize}

\textbf{A strong conclusion elevates your entire report!}
\end{quote}

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-azizi2025dsas}
Azizi, I. (2025). \emph{DSAS: Data science for actuarial sciences in
python}. \url{https://unco3892.github.io/dsas/}

\bibitem[\citeproctext]{ref-azizi2022realestate}
Azizi, I., \& Rudnytskyi, I. (2022). Improving real estate rental
estimations with visual data. \emph{Big Data and Cognitive Computing},
\emph{6}(3). \url{https://doi.org/10.3390/bdcc6030096}

\bibitem[\citeproctext]{ref-mckinney2022python}
McKinney, W. (2022). \emph{Python for data analysis: Data wrangling with
pandas, NumPy, and IPython} (3rd ed.). O'Reilly Media, Inc.

\bibitem[\citeproctext]{ref-vanderplas2016python}
VanderPlas, J. (2016). \emph{Python data science handbook: Essential
tools for working with data}. O'Reilly Media, Inc.

\end{CSLReferences}

\section*{Appendices}\label{appendices}
\addcontentsline{toc}{section}{Appendices}

\begin{quote}
\textbf{What Goes in Appendices?}

\textbf{Appendices = supplementary material} that supports but isn't
essential to your main story.

\textbf{Include in appendices:}

\begin{itemize}
\tightlist
\item
  \textbf{Additional plots and visualizations} that provide extra detail
  but don't fit the main narrative flow
\item
  \textbf{Alternative visualizations} of the same data (e.g., different
  plot types)
\item
  \textbf{Exploratory plots} that informed your analysis but aren't
  central to your findings
\item
  \textbf{Full code listings} for complex analyses
\item
  \textbf{Extended statistical tables} with detailed results
\item
  \textbf{Technical details} about data processing steps
\item
  \textbf{Sensitivity analyses} or robustness checks
\item
  \textbf{Data dictionaries} with detailed variable descriptions
\end{itemize}

\textbf{What to Keep in Main Report:}

\begin{itemize}
\tightlist
\item
  \textbf{Key visualizations} that directly answer your research
  questions
\item
  \textbf{Essential plots} for understanding your methodology
\item
  \textbf{Critical results} that support your conclusions
\item
  \textbf{Main findings} that tell your data story
\end{itemize}

\textbf{Remember:} Main report should be self-contained. Reference
appendices when needed: ``See Section~\ref{sec-appendix-plots} for
additional plots.''
\end{quote}

\subsubsection{Appendix A: Additional Exploratory
Plots}\label{sec-appendix-plots}

\subsubsection{Appendix B: Complete Code
Listings}\label{sec-appendix-code}

\subsubsection{Appendix C: Supplementary
Tables}\label{sec-appendix-tables}
\end{quote}

\end{tcolorbox}




\end{document}
